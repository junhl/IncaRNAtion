%!TEX root = main_ISMB.tex
\section{Methods}
\label{sec:methods}



We introduce a probabilistic model for the design of RNA sequences with a specific \GCContent and folding into a predefined secondary structure.
For the sake of simplicity, we choose to base this proof-of-concept implementation on a simplified free-energy function $\ES(\cdot)$, which only considers the contributions of 
stacked canonical base-pairs. We show how a modification of the dynamic programming scheme used in \RNAmutants allows for the sampling of good and diverse design candidates, in linear time and space complexities.


%To that purpose, a Boltzmann weighted distribution is used, based on a pseudo-energy function $\PE{\cdot}$ which includes contributions for both the free-energy and its putative isostericity towards a multiple sequence alignment. In this model, the probability that the nucleotide at a given position needs to be mutated (i.e. corresponds to a sequencing error) can be computed using a variant of the \emph{Inside-Outside algorithm}~\cite{Lari1990}.
%
%\subsection{Probabilistic model}
%Let $\Omega$ be an gap-free RNA alignment sequence, $S$ its associated secondary structure, 
%then any sequence $s$ is assigned a probability proportional to its Boltzmann factor
%\begin{align*}
%  \mathcal{B}(s) &= e^\frac{-\PE{s}}{RT}, &&\text{with}&\PE{s}&:=\alpha\cdot\ES(s,S)+(1-\alpha)\cdot\EI(s,S,\Omega),
%\end{align*}
%where $R$ is the Boltzmann constant, $T$ the temperature in Kelvin, $\ES(s)$ and $\EI(s,S,\Omega)$ 
%are the free-energy and isostericity contributions respectively (further described below), and $\alpha\in[0,1]$ is an arbitrary parameter that sets the relative weight for both contributions.
%
%\subsubsection{Energy contribution}
\subsection{Definitions}

A targeted secondary structure $\Target$ of length $n$ is given as a non-crossing arc-annotated sequence,  where 
$\Target_i$ stands for the base-pairing position of position $i$ in $\Target$ if any (and, reciprocally, $\Target_{\Target_i}=i$), or $-1$ otherwise. 
In addition, let us denote by $\gc(s)$ the number of occurrences of \Gb and \Cb in an RNA sequence $s$.

\subsubsection{Simplified energy model}
We use a simplified free-energy model which only includes additive contributions from stacking base-pairs. Using individual values from the Turner 2004 model (retrieved from the NNDB~\cite{Turner2010}). Given a candidate sequence $s$ for a secondary structure $\Struct$, the free-energy of any sequence $s$ of length $|\Struct|$  is given by
\begin{align*}
  \ES(s,\Struct) = \sum_{\substack{(i,j)\to (i',j')\in \Struct\\ \text{stacking pairs}}}\ES^{\beta}_{s_is_j\to s_{i'}s_{j'}} 
\end{align*}
where $\ES^{\beta}_{ab\to a'b'}$ is set to $0$ if $ab=\varnothing$ (no base-pair to stack onto), the tabulated free-energy of stacking pairs $(ab)/(a'b')$ in the Turner model if available, or $\beta\in[0,\infty]$ for non-Watson-Crick/Wobble pairs (i.e. not in $\{\Gb\Ub,\Ub\Gb,\Cb\Gb,\Gb\Cb, \Ab\Ub\text{ or }\Ub\Ab\}$). This latter parameter allows one to choose whether to simply penalize invalid base pairs ($\beta>0$), or forbid them altogether ($\beta = +\infty$). 
Position-specific sequence constraints can also be enforced at this level (details omitted for the sake of clarity) by assigning to $\ES$ a $+\infty$ penalty (leading to a null probability) in the presence of a base incompatible with a user-specified constraint mask.


\subsubsection{\GCContent weighted pseudo-Boltzmann ensemble and distribution}

In order to counterbalance the documented tendency of sampling methods to generate \Gb\Cb-rich sequences~\cite{Levin:2012kx}, we introduce a parameter $x\in\mathbb{R}^+$, whose value will influence the \GCContent of generated sequences. For any secondary structure $\Struct$, the pseudo-Boltzmann factor of a sequence $s$ is $\B^{[x]}_{\Struct}(s)$  such that
\begin{equation}
\B_{\Struct}^{[x]}(s) = e^{\frac{-\ES(s,\Struct)}{RT}}\cdot x^{\gc(s)}
\label{def:genBoltz}
\end{equation}
where $R$ is the Boltzmann constant and $T$ the temperature in Kelvin.

Summing the pseudo-Boltzmann factor over all possible sequences of a given length $|\Struct|$, one obtains the pseudo-partition function $\mathcal{Z}_{\Struct}^{[x]}$, from which one defines the pseudo-Boltzmann probability $\Prob_{\Struct}^{[x]}(s)$ of each sequence $s$, respectively such that 
\begin{align}\mathcal{Z}_{\Struct}^{[x]} &= \sum_{\substack{|s|=n}}\B_{\Struct}^{[x]}(s)& \text{and}&&
\Prob_{\Struct}^{[x]}(s) &= \frac{\B_{\Struct}^{[x]}(s)}{\mathcal{Z}_{\Struct}^{[x]}}.\label{def:distribution}\end{align}

\subsection{Sampling the pseudo-Boltzmann ensemble}

Let us now describe a linear-time algorithm to sample sequences at random in the pseudo-Boltzmann distribution. This algorithm follows the general principles of the recursive approach to random generation~\cite{Wilf1977}, pioneered in the context of RNA by the \SFold algorithm~\cite{Ding2003}. The algorithm starts by precomputing the partition function restricted to each valid interval, and then performs a series of recursive stochastic backtracks, using precomputed values to decide on the probability of each alternative. 

\subsubsection{Precomputing the pseudo-partition function}\label{sec:pf}



Firstly, a dynamic programming algorithm computes $\Z{\N,\Struct}{a,b}$ the pseudo-partition function ($x$ is omitted here for the sake of clarity) of a structure $\Struct$, assuming its (previously chosen) flanking nucleotides are $a$ and $b$ respectively, directly nested ($\N=T$) or not ($\N=F$) by some base-pair. 
Remark that the empty structure only supports the empty sequence, having energy $0$, so one has
\begin{equation}
	\Z{T,\varepsilon}{a,b}=\Z{F,\varepsilon}{a,b}=1.
	\label{eq:Z_in}
\end{equation}


The recursion considers different case, depending on whether of the first position in $\Struct$ is:
\begin{itemize}
\item Unpaired ($\Struct = \ub \Struct'$):
\begin{align}
	\Z{T,\ub \Struct'}{a,b} = \Z{F,\ub \Struct'}{a,b} &:=
      \sum_{a'\in \B}  
      x^{\gc(a')}
      \cdot\Z{F,\Struct'}{a',b}; 
\end{align}
\item Paired to last position, stacking onto an existing nesting pair ($\Struct = \op \Struct' \cp$ and $\N=T$):
\begin{align}
	\Z{T,\op \Struct' \cp}{a,b} &:=
      \sum_{a',b'\in \B^2}
			 x^{\gc(a'.b')}
			 \cdot e^{\frac{-\ES^{\beta}_{ab \to a'b'}}{RT}}
			 \cdot \Z{T,\Struct'}{a',b'}
\end{align}
\item Paired to an internal position or no stacking pair ($\Struct = \op \Struct' \cp \Struct''$ and $\N=F$, or $\Struct''\neq \varepsilon$):
\begin{align}
	\Z{\N,\op \Struct' \cp \Struct''}{a,b} &:=
			 \displaystyle
      \sum_{a',b'\in \B^2}
      x^{\gc(a'.b')}
			\cdot e^{\frac{-\ES^{\beta}_{\varnothing\to a'b'}}{RT}}
      \cdot\Z{i+1,k-1}{a',b'}
      \cdot\Z{k+1,j}{b',b} 
\label{eq:Z_rec}
\end{align}
\end{itemize}

Despite its apparent quadratic complexity, the recurrence described in Subsection~\ref{sec:pf} can be computed in linear $\Theta(n)$ time and space, owing to the fact that, on any recursive call, the position $k$ is entirely determined by $i$. 

\begin{theorem}Starting from the target structure $\Target$, Equations~\eqref{eq:Z_in} to \eqref{eq:Z_rec} can be computed in $\Theta(n)$ time and space complexity.
\end{theorem}
\begin{proof}
Clearly, there only exists a constant number of possible values for the vector $(a,b,\N)$, so the dependency in $n$ may only reside in $\Struct$. Reasoning on the length of the subintervals, one clearly see that the cumulated lengths XXXXXXXXXXXXXXXXXXXX
\end{proof}

\begin{figure}
\resizebox{\textwidth}{!}{\input{FigStochasticBacktrack.pgf}}
\caption{Stochastic backtrack procedure over an interval $[i,j]$: Either position $i$ is left unpaired (top), a base-pair $(i,j)$ is formed, stacking onto $(i+1,j-1)$ (middle), or $i$ is paired somewhere else, defining two regions on which subsequent recursive calls are needed (bottom). Positions indicated in red are assigned during this stage of the backtrack.\label{fig:stochastic}}
\end{figure}
\subsubsection{Stochastic backtrack}
Once the pseudo-partition functions have been memorized, a stochastic backtrack starts from the complete interval $[0,n-1]$ with any exterior bases $[a,b]$ and, at each step, chooses a suitable assignment for one or several positions, using probabilities derived from the precomputation, as illustrated by Figure~\ref{fig:stochastic}. One or several recursive calls over the remaining regions are then performed, as described in Algorithm~\ref{alg:back}. On each recursive call, the algorithm assigns at least one nucleotide to a -- previously unassigned -- position. Moreover, the number of executions of each loops is bounded by a constant. Consequently, the complexity of Algorithm~\ref{alg:back} is in $\Theta(n)$ time and space. 


\begin{algorithm}[t]
\DontPrintSemicolon
	\SetAlgoLined
\SetKwFunction{Backtrack}{Backtrack}
\SetKwFunction{Random}{Random}
	rand $\leftarrow$ \Random$\left(\Z{i,j}{a,b}\right)$\tcp*[r]{Draw random number in $[0,\Z{i,j}{a,b}[$}
 \lIf(\tcp*[f]{Empty sequence}){$j<i$}{\Return{$\varepsilon$}}
	\Else{
  k $\leftarrow S_i$\;
	\If(\tcp*[f]{Unpaired base}){$(k = -1)$}{
		\For{$a'\in\B$}{
			rand $\leftarrow$ rand $- x^{\gc(a')}\cdot \Z{i+1,j}{a',b}$\;
			\lIf{$\text{\rm rand}<0$}\Return{$a'.\Backtrack\left(i+1,j,a',b,\Target\right)$}\;
		}
	}
	\lElse{
		\If(\tcp*[f]{Stacking base pair}){$(k=j) \land (S_{i-1}=j+1)$}{
			\For{$(a',b')\in\B\times\B$}{
				rand $\leftarrow$ rand $-
			 	x^{\gc(a'.b')}
			 	\cdot e^{\frac{-\ES^{\beta}_{ab \to a'b'}}{RT}}
			 	\cdot \Z{i+1,j-1}{a',b'}	$\;
				\lIf{$\text{\rm rand}<0$}{
					\Return{$a'.\Backtrack\left(i+1,j-1,a',b',\Target\right). b'$}\;		
				}
			}
		}
		\lElse{
			\If(\tcp*[f]{Paired, not stacked}){$(\Target_i=k) \land (i < k \leq j)$}{
				\For{$(a',b')\in\B\times\B$}{
					rand $\leftarrow$ rand $-	
       x^{\gc(a'.b')}
					\cdot e^{\frac{-\ES^{\beta}_{\varnothing\to a'b'}}{RT}}
  	    	\cdot\Z{i+1,k-1}{a',b'}
	    	  \cdot\Z{k+1,j}{b',b}$\;	
 					\If{{\rm rand} $<0$}{
						\Return{$a'
						.\Backtrack\left(i+1,k-1,a',b',\Target\right)
						.b'
						.\Backtrack\left(k+1,j,b',b,\Target\right)
						$}\;	
					}
				}
		 }
		}
	}
 }
\caption{\protect\Backtrack$\left(i,j,a,b,\Target\right)$\label{alg:back}}
\end{algorithm}


\subsubsection{Self-adaptive sampling strategy and overall complexity}

Our goal is to produce a set of sequences whose \GCContent matches a prescribed value $gc$.
An absolute tolerance $\kappa$ may be allowed, so that the \GCContent of any valid sequence must fall in  
$[gc-\kappa,gc+\kappa]$. Since sequences of arbitrary \GCContent may be generated by Algorithm~\ref{alg:back}, we use a rejection-based approach~\cite{Bodini2010}, previously adapted by the authors in a similar context~\cite{Waldispuhl2011}. In our context, this gives an algorithm which generates $k$ valid sequences in expected time $\Theta(k\cdot n\sqrt{n})$ when $\kappa=0$ (resp. $\Theta(k\cdot n)$ when $\kappa$ is a positive constant) memory $\Theta(k\cdot n)$.
Although a complete analysis can be found in an earlier contribution~\cite{Waldispuhl2011}, let us briefly outline the strategy and arguments used to analyze the complexity.

This approach simply generates sets of sequences by repeatedly running the stochastic backtrack algorithm. The average \GCContent induced by the current value of the $x$ parameter, can then be adequately estimated from the sample, or computed exactly using recent algorithmic advances~\cite{Ponty2011}. The set of sequences is filtered to only retain valid sequences. The value of the parameter $x$ is then adapted to match the average \GCContent (induced by the value of $x$) with the targeted one.
It can be shown that the expected \GCContent is a continuous and strictly increasing monotonic function of $x$, whose limits are $0$ when $x=0$ and $n$ when $x\to +\infty$. Consequently, for any targeted \GCContent $gc\in[0\%,100\%]$, there exists a unique value $x_{gc}$ such that generated sequences feature, on the average, the right \GCContent.
In practice, a simple binary search~\cite{Waldispuhl2011} is used in our implementation, and typically converges after very few iterations. However the optimal value for $x$ can also be derived analytically using an interpolation after $\Theta(n)$ evaluations of $\Z{i,j}{a,b}$ for different candidate values of $x$, as previously noted~\cite{Waldispuhl2011} and implemented using the Fast-Fourier Transform~\cite{Senter2012}.


Regarding the overall complexity of the algorithm, it was previously established~\cite{Waldispuhl2011} that, for each value of $x$, there exists constants $\mu_x$ and $\sigma_x$ such that the distribution of \GCContent asymptotically converges towards a normal law having expectation in $\mu_x\cdot n\cdot(1+o(1))$ and standard deviation in $\sigma_x\cdot\sqrt{n}\cdot(1+o(1))$.
Furthermore, the concentration of the distribution, asserted by its limited standard deviation, therefore the expected number of attempts required to generate a valid sequence when $\kappa=0$ (resp. $\kappa\in\Omega(1/\sqrt n)$) grows linke $\Theta(\sqrt{n})$ (resp. $\Theta(1)$, i.e. a constant), leading to the announced complexities.



\subsection{Postprocessing unpaired regions: A local/global (glocal) hybrid approach}
\label{subsec:glocal_method}
Due to our simplified energy model, unpaired regions are not subject to design constraints other than the \GCContent, leading to modest probabilities for refolded design candidates to match the targeted structure. To improve these performances and test the complementarity  of our global sampling approach with previous contributions based on local search, we used the \RNAinverse software to redesign unpaired regions. We specified a constraint mask to prevent stacking base-pairs from being modified and, whenever necessary, reestablished their content {\em a posteriori}, as \RNAinverse has been witnessed to take some liberties with constraints masks. As shown in Table~\ref{table:impact_on_gc} (Supplementary material), this postprocessing does not drastically alter the \GCContent, so the glocal approach reasonably addresses the contrained \GCContent design problem.


